import pandas as pd
import numpy as np
import datetime
import time
import re

# Read in all_seasons data set with career games,minutes, and vegas line data
all_seasons=pd.read_csv('/Users/Miller/Documents/NBA 2016-17/NBA Player Gamelog Data/4_all_szns_days_and_games_since_last_game_categorical_w_career_stats_entering_next_game_and_szn_w_vegas.csv')

all_seasons = all_seasons.drop('Unnamed: 0', axis=1)

###################################################################################

###################################################################################

### Subset all_seasons to only include number of games + 1 that have been played in 2016-17 szn

### could possibly subset the number of games included in next_game_in_2016 to be fewer to include more rows

    # I.e. If the next game is the 60th game, if we determine that only the previous 40 games are relevant, then every 40 game stretch that ends with a played game could be used

    # Key thing to determine --> how many games back matters --> may want to figure out after initial model set up like this is online since this is technically the most representative sample

next_game_in_2016 = 78

length_of_2016_szn_mask = all_seasons.Game_Number <= next_game_in_2016

games_as_rows_up_to_most_recent_2016_game = all_seasons[length_of_2016_szn_mask]

###########################################################################################

###########################################################################################

# Creates dataframe with each row corresponding to a season for each player/season combo
seasons_as_rows=pd.pivot_table(games_as_rows_up_to_most_recent_2016_game, index=["season","Player"], columns=["Game_Number"], values=['PTS','2P','2P%','2PA', '3P', '3P%', '3PA', 'AST','BLK', 'DRB','FG', 'FG%', 'FGA', 'FT', 'FT%', 'FTA', 'GmSc','MP','ORB','PF','STL','TOV',"TRB",'GS','days_since_last_game','team_games_missed_since_last_game', 'career_games_played_entering_next_game','career_mins_played_entering_next_game', 'double_double', 'triple_double', 'fd_pts', 'dk_pts', 'fd_pts_per_min', 'dk_pts_per_min', 'career_fd_pts_per_min_entering_next_game','career_dk_pts_per_min_entering_next_game', 'career_fd_pts_entering_next_game', 'career_dk_pts_entering_next_game','career_fd_pts_per_game_entering_next_game', 'career_dk_pts_per_game_entering_next_game','back_to_back','one_day_off', 'two_days_off', 'three-four_days_off','five-seven_days_off', 'eight_days_plus _off','first_game_of_season', 'missed_no_games','missed_one_game', 'missed_two_games', 'missed_three-four_games','missed_five-seven_games', 'missed_eight_plus_games', 'Close Line','Close Total','Location_@', 'close_game', 'small_win', 'medium_win', 'big_win', 'small_loss', 'medium_loss', 'big_loss'])

# Captializes PTS in columns so they pass through filter properly to be deleted
pts_dict={'fd_pts':'FD_POINTS' ,'dk_pts':'DK_POINTS', 'fd_pts_per_min':'FD_POINTS_per_minute', 'dk_pts_per_min':'DK_POINTS_per_minute', 'Location_@':'location_@'}

# Changes column names
seasons_as_rows.rename(columns=pts_dict, inplace=True)

# Creates new df with correct row indices
seasons_as_rows = seasons_as_rows.reset_index()

# Mask that retains players who played in the game number that is about to played in the 2016-17 szn
played_upcoming_game_mask = ~seasons_as_rows[('MP',next_game_in_2016)].isnull()

# Called df to reuse code in section below
df = seasons_as_rows[played_upcoming_game_mask]

####################################################################################################

####################################################################################################

### Calculates weighted averages of 'stats' and total, medians and flat averages

del all_seasons
del games_as_rows_up_to_most_recent_2016_game
del seasons_as_rows

start_of_stat=1

stats = ['PTS','2P','2P%','2PA', '3P', '3P%', '3PA', 'AST','BLK', 'DRB','FG', 'FG%', 'FGA', 'FT', 'FT%', 'FTA', 'GS', 'GmSc','MP','ORB','PF','STL','TOV',"TRB",'FD_POINTS','DK_POINTS','FD_POINTS_per_minute','DK_POINTS_per_minute']

years = range(1998,2016)

weights = [0.2,0.3,0.5,0.8,1.2,1.7]

start = time.time() 
######################
for weight in weights:
    
    print("Weight: " + str(weight))

    for year in years:
        
        #print(year,weight)
    
        # Calculates the number of games in a season
        num_of_games_in_season = next_game_in_2016-1
        
        # Creates increment value for weight vector
        increment = weight / (num_of_games_in_season-1)
                
        # Creates weight vector
        weight_vector = np.array([(1-weight/2+(increment*game)) for game in range(num_of_games_in_season)])
        
        # Using first stat [PTS usually] columns to determine which games each player played in, could be any stat in theory
        start_of_first_stat = np.argmax(df.columns.get_level_values(0).str.contains(stats[0],regex=False) > 0)
        
        # Calculates last column ("end_of_year") containing data for stat/year combo in question
        end_of_first_stat = start_of_first_stat + num_of_games_in_season
        
        # Vectorized calculation for weight_resdistribution (missing_weight / present_weight)
        weight_resdistribution=np.array(np.where(df.ix[df.season == year,start_of_first_stat:end_of_first_stat].isnull().sum(axis=1) == num_of_games_in_season , 0, np.sum((pd.isnull(df.ix[df.season == year,start_of_first_stat:end_of_first_stat]) * weight_vector),axis=1)/np.sum((~pd.isnull(df.ix[df.season == year,start_of_first_stat:end_of_first_stat]) * weight_vector),axis=1)))
        
        for stat in stats:
              
            start_of_stat = np.argmax(df.columns.get_level_values(0).str.contains(stat,regex=False) > 0)
        
            # Calculates last column ("end_of_stat") containing data for stat/year combo in question
            end_of_stat = start_of_stat + num_of_games_in_season
            
            # Creates list of columns that contain the string 
            stat_cols = [column for column in df.columns if stat in str(column)]
            
            if weight == weights[0]:
                
                # Calculates avg, total and median stats for the szn up to the upcoming game
                df.ix[df.season == year, 'full_szn_avg_{}'.format(stat.lower())] = np.array(df.ix[df.season == year,start_of_stat:end_of_stat].mean(axis=1))
                df.ix[df.season == year,'full_szn_median_{}'.format(stat.lower())] = np.array(df.ix[df.season == year,start_of_stat:end_of_stat].median(axis=1))
                df.ix[df.season == year, 'full_szn_total_{0}'.format(stat.lower())] = np.array(df.ix[df.season == year,start_of_stat:end_of_stat].sum(axis=1))
                       
            ### Converts NaN values to 0 then multiplies the row values by the newly calculated weight vector 
            df.ix[df.season==year,'wtd_avg_{0}_{1}'.format(weight,stat.lower())] = np.array(np.sum((((~(df.ix[df.season == year,start_of_stat:end_of_stat].isnull()) * weight_vector)).multiply(weight_resdistribution,axis='index') + (~(df.ix[df.season == year,start_of_stat:end_of_stat].isnull()) * weight_vector)) * df.ix[df.season == year,start_of_stat:end_of_stat],axis=1)/num_of_games_in_season)

end = time.time()
print("Time for Weighted Average: " +str(end - start))

# ############################################################################################
# ###########################################################################################################################################

# Calculates avg, total and median for each stat over each 'stretch' in game_stretches

game_stretches = [1,2,3,5,8,12,16,20,25,30,35,40,45,50,55,60]

# Calculates the number of games in a season
num_of_games_in_season = next_game_in_2016-1

start = time.time()
for stat in stats:
    
    start_of_stat = np.argmax(df.columns.get_level_values(0).str.contains(stat,regex=False) > 0)
        
    # Calculates last column ("end_of_stat") containing data for stat/year combo in question
    end_of_stat = start_of_stat + num_of_games_in_season
    
    for stretch in game_stretches:
        
        # Calculates avg, total and median stats for the szn up to the upcoming game
        df.ix[:, 'last{0}_avg_{1}'.format(stretch,stat.lower())] = np.array(df.ix[:,end_of_stat-stretch:end_of_stat].mean(axis=1))
        df.ix[:, 'last{0}_median_{1}'.format(stretch,stat.lower())] = np.array(df.ix[:,end_of_stat-stretch:end_of_stat].median(axis=1))
        df.ix[:, 'last{0}_total_{1}'.format(stretch,stat.lower())] = np.array(df.ix[:,end_of_stat-stretch:end_of_stat].sum(axis=1))

end = time.time()
print("Time for Periodic Averages: " + str(end - start))

############################################################################################
############################################################################################

### Drop all gamelog data except for the upcoming game number

# Removes multi-indexing from column names and creates list of column names 
seasons_as_rows = pd.DataFrame(df.to_records())

# Drops 'index' column
seasons_as_rows = seasons_as_rows.drop('index',axis=1)

# Creates list of column names
cols = seasons_as_rows.columns.tolist()

stats_with_game_nums_to_remove = ['PTS','2P','2P%','2PA', '3P', '3P%', '3PA', 'AST','BLK', 'DRB','FG', 'FG%', 'FGA', 'FT', 'FT%', 'FTA', 'GS','GmSc','MP','ORB','PF','STL','TOV',"TRB",'POINTS']

# Creates list of lower case stats to use to find columns that don't have associated game numbers in column headings
stats_lower = [stat.lower() for stat in stats_with_game_nums_to_remove]

### Createst list of column names containing gamelog data from game 1 through game before upcoming game
cols_to_remove = []
# Pass np.argmax function to skip over season and player column names
for i in range(np.argmax(seasons_as_rows.columns.str.contains('Player'))+1,len(cols)):
    # Checks if any stat in the list of stats is contained in the given column name
    if (not any(stat in cols[i] for stat in stats_lower)) | ('days' in cols[i]) | ('career' in cols[i]) | ('team_games_missed' in cols[i]) | ("DK_POINTS" in cols[i]) | ("FD_POINTS" in cols[i]):
        # Checks to ensure that the last portion of the string (game number) is less than next_game_in_2016
        if int(re.search('\d+',str(cols[i])[-5:]).group(0)) < next_game_in_2016:
            cols_to_remove.append(cols[i])

# Drops gamelog columns
seasons_as_rows = seasons_as_rows.drop(cols_to_remove, axis=1)

cols_list = seasons_as_rows.columns.tolist()

# Removes extra spaces, commas and quotation marks from non-next game columns that were added from removing multi-indexing in cols_list
for i in range(len(cols_list)):
    if (i == 0) | (i == 1 ) | ('days' in cols_list[i]) | ('career' in cols_list[i]) | ('location' in cols_list[i]) | ('missed' in cols_list[i]) | ("back_to_back" in cols_list[i]) | ('line' in cols_list[i]) | ('close' in cols_list[i]) | ('Total' in cols_list[i]) | ("Line" in cols_list[i]) | ('one_day_off' in cols_list[i]) | ("first_game_of_season" in cols_list[i]) | ('win' in cols_list[i]) | ('loss' in cols_list[i]) | (any(stat in cols_list[i] for stat in stats_lower)):
        #print(cols_list[i].partition("(")[-1].rpartition(",")[0].strip("'"))
        cols_list[i]=cols_list[i].partition("(")[-1].rpartition(",")[0].strip("'")

# Creates dictionary that can be used to rename column names in seasons_as_rows
rename_columns_dict = {old:new for (old,new) in zip(seasons_as_rows.columns,cols_list)}      

# Renames columns to remove extra spaces, commas and quotation marks from non-next game columns
seasons_as_rows.rename(columns=rename_columns_dict, inplace=True)

# Fills remaining NA cells with 0 --> do after weighted average to avoid having to re-write weighted average code
seasons_as_rows = seasons_as_rows.fillna(value=0)

#########################################################################################

### Merges seasons_as_rows_thru_next_game with draft data

# Reads in draft data
draft=pd.read_csv("/Users/Miller/Documents/NBA 2016-17/NBA Draft Data/nba_draft_1995_to_2015.csv")

### Duplicate Players in the Draft data set:
# Corey Brewer
# Marcus Williams
# Marcus Thornton

################################################################################################

### Removing/editing duplicated players

# Remove Marcus Thornton who never played in NBA from draft data set

thornton_mask = (draft.Player == "Marcus Thornton") & (draft.Pick == 45)

draft=draft[~thornton_mask]

# Remove irrelevant Corey Brewer from draft data set

brewer_mask = (draft.Player == "Corey Brewer") & (draft.Pick == 51)

draft=draft[~brewer_mask]

#################################################################################################

### Change name of "Marcus Williams" to "Marcus Elliott Williams" to mirror change made to "wide"

williams_mask = (draft.Player == "Marcus Williams") & (draft.Pick == 33)

draft.ix[williams_mask,"Player"]="Marcus Elliott Williams"

#################################################################################################

### Merge with draft data

seasons_as_rows_draft = pd.merge(seasons_as_rows, draft, on="Player", how='left')

seasons_as_rows_draft = seasons_as_rows_draft.drop('Yrs',axis=1)

del seasons_as_rows #???

###########################################################################################

### Merging ADP data

# Importing ADP data

for year in range(10,17):
    one_year = pd.read_csv("/Users/Miller/Documents/NBA 2016-17/ADP Data/20{0}-{1}_nba_adp.csv".format(year,year+1))
    one_year["season"] = 2000+year
    if year == 10:
        all_adp=one_year
    else:
        all_adp = all_adp.append(one_year)

adp_wide=pd.pivot_table(all_adp, index=["Name", 'season'], values=['Y!Adp9','ESPNAdp8'])

adp_wide = adp_wide.reset_index()

# Merge Step
seasons_as_rows_draft_adp = pd.merge(seasons_as_rows_draft, adp_wide, left_on=['Player', 'season'], right_on=['Name', 'season'], how='left')

# Creates one hot for whether or not there was adp present
seasons_as_rows_draft_adp['adp_data_present']=np.where(seasons_as_rows_draft_adp.ix[:,'season'].astype(int) < 2010, 0, 1)

# Drops "Name" and 'Draft' column
seasons_as_rows_draft_adp.drop(["Name",'Draft'], axis=1, inplace = True)

# Fills NA "Pick" cells with 100
seasons_as_rows_draft_adp.ix[:,'Pick'] = seasons_as_rows_draft_adp.ix[:,'Pick'].fillna(value=100)

# Fills NA ADP cells with 300 (Create variable indicating whether ADP stats were available?)
seasons_as_rows_draft_adp.ix[:,['ESPNAdp8', 'Y!Adp9']] = seasons_as_rows_draft_adp.ix[:,['ESPNAdp8', 'Y!Adp9']].fillna(value=300)

### Reads in dataset of all players to play in NBA history with relevant duplicates fixed
players_full = pd.read_csv("/Users/Miller/Documents/NBA 2016-17/every_player_in_nba_history_no_duplicates_for_1998_plus.csv")

seasons_as_rows_draft_adp_size = pd.merge(seasons_as_rows_draft_adp, players_full, on='Player', how='left')

del seasons_as_rows_draft #??

#####################################################################################################################

### Calculating age for each player for each year at start of season (each row essentially)
birthday_vector = pd.to_datetime(seasons_as_rows_draft_adp_size['Birth Date'])

# Calculates vector of "season" column as datetime object
season_vector = pd.to_datetime(seasons_as_rows_draft_adp_size['season'].astype(int), yearfirst=True, format="%Y")

# Accounts for difference in season_vector and start of actual season (season_vector starts on Jan. 1)
days_from_jan_1_to_start_of_season = datetime.timedelta(days = 300)

#####################################################################################################################
#####################################################################################################################

# Rodeo works before this section

# Creates vector of datetime objects containing age in number of days at start of season
age_at_start_of_season_vector = (season_vector - birthday_vector) + days_from_jan_1_to_start_of_season

# Creates list of ages at start of season without the datetime formatting
formatted_age_list = [str(age)[:5] if len(str(age))==19 else str(age)[:4] for age in age_at_start_of_season_vector]

# Creates new column for age at start of season
seasons_as_rows_draft_adp_size['age_at_start_of_season'] = formatted_age_list

# Removes unnamed columns
unnamed_cols = list(seasons_as_rows_draft_adp_size.columns[seasons_as_rows_draft_adp_size.columns.str.contains("Unnamed")])
# unnamed_cols.extend(['Ht','College','Birth Date'])

seasons_as_rows_draft_adp_size.drop(unnamed_cols,axis=1,inplace=True)

# Removes unwanted 'Ht' column
seasons_as_rows_draft_adp_size.drop(['Ht','College','Birth Date',],axis=1,inplace=True)

# Fills remaining NA cells with 0 
seasons_as_rows_draft_adp_size = seasons_as_rows_draft_adp_size.fillna(value=0)

# Converts 'Pos' into a one-hot variable
seasons_as_rows_draft_adp_size = pd.get_dummies(seasons_as_rows_draft_adp_size,columns=['Pos'])

######################################################################################################

######################################################################################################

# Reading in prior data sets

first_year_priors = pd.read_csv("/Users/Miller/Documents/NBA 2016-17/RF & xgBoost Prior Modeling Data/Data Sets With Predicted Priors/predicted_first_year_priors.csv")
first_year_priors = first_year_priors.ix[:,['Player','first_year_season' , "xgb_pred_first_year_('reg_szn_total_fd_pts', '')" , "rf_pred_first_year_('reg_szn_total_fd_pts', '')" , "avg_pred_first_year_('reg_szn_total_fd_pts', '')" , "xgb_pred_first_year_('reg_szn_total_dk_pts', '')" , "rf_pred_first_year_('reg_szn_total_dk_pts', '')" ,	"avg_pred_first_year_('reg_szn_total_dk_pts', '')" , "xgb_pred_first_year_('FD_prior_^0.7_of_total', '')" , "rf_pred_first_year_('FD_prior_^0.7_of_total', '')" , "avg_pred_first_year_('FD_prior_^0.7_of_total', '')" , "xgb_pred_first_year_('DK_prior_^0.7_of_total', '')" , "rf_pred_first_year_('DK_prior_^0.7_of_total', '')" , "avg_pred_first_year_('DK_prior_^0.7_of_total', '')"]]
first_year_priors.rename(columns={'first_year_season':'season' , "xgb_pred_first_year_('reg_szn_total_fd_pts', '')" : "xgb_pred_('reg_szn_total_fd_pts', '')" , "rf_pred_first_year_('reg_szn_total_fd_pts', '')" : "rf_pred_('reg_szn_total_fd_pts', '')" , "avg_pred_first_year_('reg_szn_total_fd_pts', '')" : "avg_pred_('reg_szn_total_fd_pts', '')" , "xgb_pred_first_year_('reg_szn_total_dk_pts', '')" : "xgb_pred_('reg_szn_total_dk_pts', '')" , "rf_pred_first_year_('reg_szn_total_dk_pts', '')" : "rf_pred_('reg_szn_total_dk_pts', '')" , "avg_pred_first_year_('reg_szn_total_dk_pts', '')" : "avg_pred_('reg_szn_total_dk_pts', '')" , "xgb_pred_first_year_('FD_prior_^0.7_of_total', '')" : "xgb_pred_('FD_prior_^0.7_of_total', '')" , "rf_pred_first_year_('FD_prior_^0.7_of_total', '')" : "rf_pred_('FD_prior_^0.7_of_total', '')"  , "avg_pred_first_year_('FD_prior_^0.7_of_total', '')" : "avg_pred_('FD_prior_^0.7_of_total', '')"  , "xgb_pred_first_year_('DK_prior_^0.7_of_total', '')" : "xgb_pred_('DK_prior_^0.7_of_total', '')"  , "rf_pred_first_year_('DK_prior_^0.7_of_total', '')" : "rf_pred_('DK_prior_^0.7_of_total', '')" , "avg_pred_first_year_('DK_prior_^0.7_of_total', '')" : "avg_pred_('DK_prior_^0.7_of_total', '')"}, inplace=True)

second_year_priors = pd.read_csv("/Users/Miller/Documents/NBA 2016-17/RF & xgBoost Prior Modeling Data/Data Sets With Predicted Priors/predicted_second_year_priors.csv")
second_year_priors = second_year_priors.ix[:,['Player','second_year_season' , "xgb_pred_second_year_('reg_szn_total_fd_pts', '')" , "rf_pred_second_year_('reg_szn_total_fd_pts', '')" , "avg_pred_second_year_('reg_szn_total_fd_pts', '')" , "xgb_pred_second_year_('reg_szn_total_dk_pts', '')" , "rf_pred_second_year_('reg_szn_total_dk_pts', '')" ,	"avg_pred_second_year_('reg_szn_total_dk_pts', '')" , "xgb_pred_second_year_('FD_prior_^0.7_of_total', '')" , "rf_pred_second_year_('FD_prior_^0.7_of_total', '')" , "avg_pred_second_year_('FD_prior_^0.7_of_total', '')" , "xgb_pred_second_year_('DK_prior_^0.7_of_total', '')" , "rf_pred_second_year_('DK_prior_^0.7_of_total', '')" , "avg_pred_second_year_('DK_prior_^0.7_of_total', '')"]]
second_year_priors.rename(columns={'second_year_season':'season' , "xgb_pred_second_year_('reg_szn_total_fd_pts', '')" : "xgb_pred_('reg_szn_total_fd_pts', '')" , "rf_pred_second_year_('reg_szn_total_fd_pts', '')" : "rf_pred_('reg_szn_total_fd_pts', '')" , "avg_pred_second_year_('reg_szn_total_fd_pts', '')" : "avg_pred_('reg_szn_total_fd_pts', '')" , "xgb_pred_second_year_('reg_szn_total_dk_pts', '')" : "xgb_pred_('reg_szn_total_dk_pts', '')" , "rf_pred_second_year_('reg_szn_total_dk_pts', '')" : "rf_pred_('reg_szn_total_dk_pts', '')" , "avg_pred_second_year_('reg_szn_total_dk_pts', '')" : "avg_pred_('reg_szn_total_dk_pts', '')" , "xgb_pred_second_year_('FD_prior_^0.7_of_total', '')" : "xgb_pred_('FD_prior_^0.7_of_total', '')" , "rf_pred_second_year_('FD_prior_^0.7_of_total', '')" : "rf_pred_('FD_prior_^0.7_of_total', '')"  , "avg_pred_second_year_('FD_prior_^0.7_of_total', '')" : "avg_pred_('FD_prior_^0.7_of_total', '')"  , "xgb_pred_second_year_('DK_prior_^0.7_of_total', '')" : "xgb_pred_('DK_prior_^0.7_of_total', '')"  , "rf_pred_second_year_('DK_prior_^0.7_of_total', '')" : "rf_pred_('DK_prior_^0.7_of_total', '')" , "avg_pred_second_year_('DK_prior_^0.7_of_total', '')" : "avg_pred_('DK_prior_^0.7_of_total', '')"}, inplace=True)

third_year_priors = pd.read_csv("/Users/Miller/Documents/NBA 2016-17/RF & xgBoost Prior Modeling Data/Data Sets With Predicted Priors/predicted_third_year_priors.csv")
third_year_priors = third_year_priors.ix[:,['Player','third_year_season' , "xgb_pred_third_year_('reg_szn_total_fd_pts', '')" , "rf_pred_third_year_('reg_szn_total_fd_pts', '')" , "avg_pred_third_year_('reg_szn_total_fd_pts', '')" , "xgb_pred_third_year_('reg_szn_total_dk_pts', '')" , "rf_pred_third_year_('reg_szn_total_dk_pts', '')" ,	"avg_pred_third_year_('reg_szn_total_dk_pts', '')" , "xgb_pred_third_year_('FD_prior_^0.7_of_total', '')" , "rf_pred_third_year_('FD_prior_^0.7_of_total', '')" , "avg_pred_third_year_('FD_prior_^0.7_of_total', '')" , "xgb_pred_third_year_('DK_prior_^0.7_of_total', '')" , "rf_pred_third_year_('DK_prior_^0.7_of_total', '')" , "avg_pred_third_year_('DK_prior_^0.7_of_total', '')"]]
third_year_priors.rename(columns={'third_year_season':'season' , "xgb_pred_third_year_('reg_szn_total_fd_pts', '')" : "xgb_pred_('reg_szn_total_fd_pts', '')" , "rf_pred_third_year_('reg_szn_total_fd_pts', '')" : "rf_pred_('reg_szn_total_fd_pts', '')" , "avg_pred_third_year_('reg_szn_total_fd_pts', '')" : "avg_pred_('reg_szn_total_fd_pts', '')" , "xgb_pred_third_year_('reg_szn_total_dk_pts', '')" : "xgb_pred_('reg_szn_total_dk_pts', '')" , "rf_pred_third_year_('reg_szn_total_dk_pts', '')" : "rf_pred_('reg_szn_total_dk_pts', '')" , "avg_pred_third_year_('reg_szn_total_dk_pts', '')" : "avg_pred_('reg_szn_total_dk_pts', '')" , "xgb_pred_third_year_('FD_prior_^0.7_of_total', '')" : "xgb_pred_('FD_prior_^0.7_of_total', '')" , "rf_pred_third_year_('FD_prior_^0.7_of_total', '')" : "rf_pred_('FD_prior_^0.7_of_total', '')"  , "avg_pred_third_year_('FD_prior_^0.7_of_total', '')" : "avg_pred_('FD_prior_^0.7_of_total', '')"  , "xgb_pred_third_year_('DK_prior_^0.7_of_total', '')" : "xgb_pred_('DK_prior_^0.7_of_total', '')"  , "rf_pred_third_year_('DK_prior_^0.7_of_total', '')" : "rf_pred_('DK_prior_^0.7_of_total', '')" , "avg_pred_third_year_('DK_prior_^0.7_of_total', '')" : "avg_pred_('DK_prior_^0.7_of_total', '')"}, inplace=True)

fourth_year_priors = pd.read_csv("/Users/Miller/Documents/NBA 2016-17/RF & xgBoost Prior Modeling Data/Data Sets With Predicted Priors/predicted_fourth_year_priors.csv")
fourth_year_priors = fourth_year_priors.ix[:,['Player','fourth_year_season' , "xgb_pred_fourth_year_('reg_szn_total_fd_pts', '')" , "rf_pred_fourth_year_('reg_szn_total_fd_pts', '')" , "avg_pred_fourth_year_('reg_szn_total_fd_pts', '')" , "xgb_pred_fourth_year_('reg_szn_total_dk_pts', '')" , "rf_pred_fourth_year_('reg_szn_total_dk_pts', '')" ,	"avg_pred_fourth_year_('reg_szn_total_dk_pts', '')" , "xgb_pred_fourth_year_('FD_prior_^0.7_of_total', '')" , "rf_pred_fourth_year_('FD_prior_^0.7_of_total', '')" , "avg_pred_fourth_year_('FD_prior_^0.7_of_total', '')" , "xgb_pred_fourth_year_('DK_prior_^0.7_of_total', '')" , "rf_pred_fourth_year_('DK_prior_^0.7_of_total', '')" , "avg_pred_fourth_year_('DK_prior_^0.7_of_total', '')"]]
fourth_year_priors.rename(columns={'fourth_year_season':'season' , "xgb_pred_fourth_year_('reg_szn_total_fd_pts', '')" : "xgb_pred_('reg_szn_total_fd_pts', '')" , "rf_pred_fourth_year_('reg_szn_total_fd_pts', '')" : "rf_pred_('reg_szn_total_fd_pts', '')" , "avg_pred_fourth_year_('reg_szn_total_fd_pts', '')" : "avg_pred_('reg_szn_total_fd_pts', '')" , "xgb_pred_fourth_year_('reg_szn_total_dk_pts', '')" : "xgb_pred_('reg_szn_total_dk_pts', '')" , "rf_pred_fourth_year_('reg_szn_total_dk_pts', '')" : "rf_pred_('reg_szn_total_dk_pts', '')" , "avg_pred_fourth_year_('reg_szn_total_dk_pts', '')" : "avg_pred_('reg_szn_total_dk_pts', '')" , "xgb_pred_fourth_year_('FD_prior_^0.7_of_total', '')" : "xgb_pred_('FD_prior_^0.7_of_total', '')" , "rf_pred_fourth_year_('FD_prior_^0.7_of_total', '')" : "rf_pred_('FD_prior_^0.7_of_total', '')"  , "avg_pred_fourth_year_('FD_prior_^0.7_of_total', '')" : "avg_pred_('FD_prior_^0.7_of_total', '')"  , "xgb_pred_fourth_year_('DK_prior_^0.7_of_total', '')" : "xgb_pred_('DK_prior_^0.7_of_total', '')"  , "rf_pred_fourth_year_('DK_prior_^0.7_of_total', '')" : "rf_pred_('DK_prior_^0.7_of_total', '')" , "avg_pred_fourth_year_('DK_prior_^0.7_of_total', '')" : "avg_pred_('DK_prior_^0.7_of_total', '')"}, inplace=True)

fifth_year_priors = pd.read_csv("/Users/Miller/Documents/NBA 2016-17/RF & xgBoost Prior Modeling Data/Data Sets With Predicted Priors/predicted_fifth_year_priors.csv")
fifth_year_priors = fifth_year_priors.ix[:,['Player','fifth_year_season' , "xgb_pred_fifth_year_('reg_szn_total_fd_pts', '')" , "rf_pred_fifth_year_('reg_szn_total_fd_pts', '')" , "avg_pred_fifth_year_('reg_szn_total_fd_pts', '')" , "xgb_pred_fifth_year_('reg_szn_total_dk_pts', '')" , "rf_pred_fifth_year_('reg_szn_total_dk_pts', '')" ,	"avg_pred_fifth_year_('reg_szn_total_dk_pts', '')" , "xgb_pred_fifth_year_('FD_prior_^0.7_of_total', '')" , "rf_pred_fifth_year_('FD_prior_^0.7_of_total', '')" , "avg_pred_fifth_year_('FD_prior_^0.7_of_total', '')" , "xgb_pred_fifth_year_('DK_prior_^0.7_of_total', '')" , "rf_pred_fifth_year_('DK_prior_^0.7_of_total', '')" , "avg_pred_fifth_year_('DK_prior_^0.7_of_total', '')"]]
fifth_year_priors.rename(columns={'fifth_year_season':'season' , "xgb_pred_fifth_year_('reg_szn_total_fd_pts', '')" : "xgb_pred_('reg_szn_total_fd_pts', '')" , "rf_pred_fifth_year_('reg_szn_total_fd_pts', '')" : "rf_pred_('reg_szn_total_fd_pts', '')" , "avg_pred_fifth_year_('reg_szn_total_fd_pts', '')" : "avg_pred_('reg_szn_total_fd_pts', '')" , "xgb_pred_fifth_year_('reg_szn_total_dk_pts', '')" : "xgb_pred_('reg_szn_total_dk_pts', '')" , "rf_pred_fifth_year_('reg_szn_total_dk_pts', '')" : "rf_pred_('reg_szn_total_dk_pts', '')" , "avg_pred_fifth_year_('reg_szn_total_dk_pts', '')" : "avg_pred_('reg_szn_total_dk_pts', '')" , "xgb_pred_fifth_year_('FD_prior_^0.7_of_total', '')" : "xgb_pred_('FD_prior_^0.7_of_total', '')" , "rf_pred_fifth_year_('FD_prior_^0.7_of_total', '')" : "rf_pred_('FD_prior_^0.7_of_total', '')"  , "avg_pred_fifth_year_('FD_prior_^0.7_of_total', '')" : "avg_pred_('FD_prior_^0.7_of_total', '')"  , "xgb_pred_fifth_year_('DK_prior_^0.7_of_total', '')" : "xgb_pred_('DK_prior_^0.7_of_total', '')"  , "rf_pred_fifth_year_('DK_prior_^0.7_of_total', '')" : "rf_pred_('DK_prior_^0.7_of_total', '')" , "avg_pred_fifth_year_('DK_prior_^0.7_of_total', '')" : "avg_pred_('DK_prior_^0.7_of_total', '')"}, inplace=True)

all_priors=first_year_priors.append(second_year_priors).append(third_year_priors).append(fourth_year_priors).append(fifth_year_priors)

final_training_set = pd.merge(seasons_as_rows_draft_adp_size, all_priors, on=['Player','season'], how = 'left')

### Should make ADP and 'pick' categorical and include a category for when adp didnt exist

final_training_set.to_csv('/Users/Miller/Documents/NBA 2016-17/Daily Modeling Data/Training Set/daily_training_set_with_priors_4_8.csv')





